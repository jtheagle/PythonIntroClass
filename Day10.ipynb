{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55176f8d-4890-4f4a-93bf-2d9edbbee0d7",
   "metadata": {},
   "source": [
    "<h1>Class 10: Introduction to Web Scraping and APIs</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbf282-626d-482b-96db-8f7c3a0ebf35",
   "metadata": {},
   "source": [
    "<h2>Understanding web scraping and its applications</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81110034-54f8-4996-b8c5-20af4d47cdb2",
   "metadata": {},
   "source": [
    "<p><span style=\"font-size:16px;\">It&#39;s important to note that while web scraping can be a powerful tool for data acquisition and analysis, it should be used responsibly and ethically, respecting the rights and policies of the websites being scraped.</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f298b-1dfa-4603-aae1-df73c6a7beaa",
   "metadata": {},
   "source": [
    "<p><span style=\"font-size:16px;\">Web scraping is the process of extracting data from websites using automated methods. It involves fetching the HTML content of a web page, parsing and extracting the desired information, and then storing or utilizing that data for various purposes. Here&#39;s an explanation of web scraping and its applications:</span></p>\n",
    "\n",
    "<ol>\n",
    "\t<li><span style=\"font-size:16px;\">How Web Scraping Works: Web scraping typically follows these steps:</span></li>\n",
    "</ol>\n",
    "\n",
    "<ul style=\"margin-left: 40px;\">\n",
    "\t<li><span style=\"font-size:16px;\">Sending an HTTP request to a website and fetching the HTML content of the desired web page.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\">Parsing the HTML to extract specific elements such as text, images, links, tables, or other structured data.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\">Transforming and cleaning the extracted data to make it usable.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\">Storing the scraped data or using it for analysis, visualization, research, or any other intended purpose.</span></li>\n",
    "</ul>\n",
    "\n",
    "<ol start=\"2\">\n",
    "\t<li><span style=\"font-size:16px;\">Applications of Web Scraping: Web scraping has a wide range of applications across various domains:</span></li>\n",
    "</ol>\n",
    "\n",
    "<ul style=\"margin-left: 40px;\">\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Data Collection</strong>: Web scraping allows you to gather large amounts of data from websites efficiently. This data can be used for market research, competitor analysis, sentiment analysis, pricing comparisons, or any other data-driven decision-making process.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Content Aggregation</strong>: Scraping content from different websites enables you to aggregate information from multiple sources and create comprehensive databases or informational resources.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Lead Generation</strong>: Web scraping can help in extracting contact information, email addresses, or other relevant details from websites for lead generation purposes.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Market Research</strong>: Scraping data from e-commerce websites or social media platforms can provide insights into market trends, customer behavior, or product reviews.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>News Monitoring</strong>: Web scraping can be used to monitor news articles or blogs to gather real-time information, detect trends, or track mentions of specific topics or keywords.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Financial Data Analysis</strong>: Scraping financial data from websites allows for analysis of stock prices, market trends, financial reports, and other related data.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Job Posting Analysis</strong>: Scraping job portals can provide information on job postings, salaries, skills in demand, or companies hiring in specific industries.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Academic Research</strong>: Web scraping assists researchers in collecting data for academic studies, sentiment analysis, sentiment tracking, or monitoring public opinion on specific topics.</span></li>\n",
    "</ul>\n",
    "\n",
    "<ol start=\"3\">\n",
    "\t<li><span style=\"font-size:16px;\">Legal and Ethical Considerations: When engaging in web scraping, it is important to consider legal and ethical aspects:</span></li>\n",
    "</ol>\n",
    "\n",
    "<ul style=\"margin-left: 40px;\">\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Terms of Service</strong>: Ensure compliance with the website&#39;s terms of service or usage policy. Some websites explicitly prohibit or restrict web scraping.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Copyright and Intellectual Property</strong>: Respect copyright and intellectual property rights by avoiding scraping of copyrighted content or confidential data.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Respectful Crawling</strong>: Be mindful of the server load and avoid causing disruption to the target website&#39;s performance by implementing appropriate delays and throttling mechanisms.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>Personal Data and Privacy</strong>: Be cautious when dealing with personal data and sensitive information. Ensure compliance with data protection regulations and respect user privacy.</span></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a119308-d6fb-44a4-916e-aca6b63f5a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b1d5370-3fb8-4a9e-93ac-ca4be157dd8b",
   "metadata": {},
   "source": [
    "<h2>Introduction to HTML parsing and data extraction using BeautifulSoup</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f62a9-463c-41a1-afcc-1d0e21fdc4c8",
   "metadata": {},
   "source": [
    "<ol>\n",
    "\t<li><span style=\"font-size:16px;\">Installation: To get started, you need to install BeautifulSoup. You can use <code>pip</code> to install it by running the following command in your terminal or command prompt:</span></li>\n",
    "</ol>\n",
    "\n",
    "<p><span style=\"font-size:16px;\"><code>pip install beautifulsoup4 </code></span></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<ol start=\"2\">\n",
    "\t<li><span style=\"font-size:16px;\">Importing BeautifulSoup: To use BeautifulSoup in your Python code, you need to import it. Typically, you import it like this:</span></li>\n",
    "</ol>\n",
    "\n",
    "<p><span style=\"font-size:16px;\"><code>from bs4 import BeautifulSoup</code></span></p>\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0cb68f-f13d-48e6-b69b-07c2f85e70bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ad3e6c5-5435-4611-86c4-fc995cbe1b5c",
   "metadata": {},
   "source": [
    "<ol start=\"3\">\n",
    "\t<li><span style=\"font-size:16px;\">Parsing HTML: To parse an HTML document using BeautifulSoup, you need to create a <code>BeautifulSoup</code> object by providing the HTML content and a parser. BeautifulSoup supports different parsers, such as <code>&#39;html.parser&#39;</code>, <code>&#39;lxml&#39;</code>, or <code>&#39;html5lib&#39;</code>.</span></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a21ec-0426-4efd-ab12-00f62387d713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_content = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title>My Webpage</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Welcome to my webpage</h1>\n",
    "    <p>This is a paragraph of text.</p>\n",
    "    <ul>\n",
    "        <li>Item 1</li>\n",
    "        <li>Item 2</li>\n",
    "        <li>Item 3</li>\n",
    "    </ul>\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61fb40-5ca5-4172-af9f-3da5c98f3aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f4c39af-5387-474b-81cd-2ea76d240f47",
   "metadata": {
    "tags": []
   },
   "source": [
    "<ol start=\"3\">\n",
    "\t<li><span style=\"font-size:16px;\">Navigating the Document Structure: Once you have the <code>BeautifulSoup</code> object, you can navigate the HTML document&#39;s structure using various methods and properties provided by BeautifulSoup. Some common ones include:</span></li>\n",
    "</ol>\n",
    "\n",
    "<ul style=\"margin-left: 40px;\">\n",
    "\t<li><span style=\"font-size:16px;\"><code>soup.title</code>: Accesses the title tag.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><code>soup.body</code>: Accesses the body tag.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><code>soup.find(&#39;tag&#39;)</code>: Finds the first occurrence of the specified tag.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><code>soup.find_all(&#39;tag&#39;)</code>: Finds all occurrences of the specified tag.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><code>element.text</code>: Extracts the text content of an element.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><code>element[&#39;attribute&#39;]</code>: Accesses the value of a specific attribute of an element.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3348d-a8a6-4a7c-971e-381565cc51ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e6fd2f-752e-4a8c-a5cb-a238b9edfe59",
   "metadata": {},
   "source": [
    "<ol start=\"5\">\n",
    "\t<li><span style=\"font-size:16px;\">Data Extraction: BeautifulSoup provides various methods to extract data from HTML elements based on different criteria like tag names, class names, attribute values, or CSS selectors. Some commonly used methods include:</span></li>\n",
    "</ol>\n",
    "\n",
    "<ul style=\"margin-left: 40px;\">\n",
    "\t<li><span style=\"font-size:16px;\"><code>find()</code>: Finds the first occurrence of an element based on a specific criterion.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><code>find_all()</code>: Finds all occurrences of elements based on a specific criterion.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><code>select()</code>: Finds elements based on CSS selectors.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe4148-2eb9-4cd9-b524-464a73ffae4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94f9a70c-7f7d-4058-a25a-951573636c68",
   "metadata": {},
   "source": [
    "<h2>Making HTTP requests and interacting with APIs</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b619f-c955-40e2-ba4e-ac5a94815efa",
   "metadata": {},
   "source": [
    "<ol start=\"1\">\n",
    "\t<li><span style=\"font-size:16px;\">Working with the request library</span></li>\n",
    "</ol>\n",
    "\n",
    "<ul style=\"margin-left: 40px;\">\n",
    "\t<li><span style=\"font-size:16px;\">Installing the Requests Library: Before you start, you need to install the <code>requests</code> library. You can use <code>pip</code> to install it by running the following command in your terminal or command prompt:&nbsp;</span></li>\n",
    "</ul>\n",
    "\n",
    "<p><span style=\"font-size:16px;\"><code>pip install requests</code></span></p>\n",
    "\n",
    "<ul style=\"margin-left: 40px;\">\n",
    "\t<li><span style=\"font-size:16px;\">Importing the Requests Library: To use the <code>requests</code> library in your Python code, you need to import it:</span></li>\n",
    "</ul>\n",
    "\n",
    "<p><span style=\"font-size:16px;\"><code>import requests</code></span></p>\n",
    "\n",
    "<ul style=\"margin-left: 40px;\">\n",
    "\t<li><span style=\"font-size:16px;\"><strong>GET Requests</strong>: To make a GET request to a URL and retrieve data from the server, you can use the <code>requests.get()</code> method.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\"><strong>POST Requests</strong>: To make a POST request and send data to the server, you can use the <code>requests.post()</code> method.&nbsp;</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcb8ec-f557-42be-8399-d9b316fa1b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31fc9948-a29f-4cac-b085-a52f6916b748",
   "metadata": {},
   "source": [
    "<h2>Parsing JSON responses and working with API data in Python</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d423fe8f-b914-4e38-9962-89757405820d",
   "metadata": {},
   "source": [
    "<ol>\n",
    "\t<li><span style=\"font-size:16px;\">Handling JSON Responses: Many APIs return data in JSON format. You can use the <code>.json()</code> method of the response object to parse the JSON data into a Python dictionary.</span></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87483cd7-5be2-4de4-b486-3d941954cf80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec3cbaa8-64ce-43a3-b35b-6204c1f39eb9",
   "metadata": {},
   "source": [
    "<ol start=\"2\">\n",
    "\t<li><span style=\"font-size:16px;\">Handling Query Parameters: You can pass query parameters in the URL for GET requests using the <code>params</code> parameter of the <code>requests.get()</code> method.</span></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4698163-f54d-41d6-8500-605542f75c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f23c7e1-819f-4cb9-ac3d-c1897a38fcde",
   "metadata": {},
   "source": [
    "<ol start=\"3\">\n",
    "\t<li><span style=\"font-size:16px;\">Handling Authentication: Some APIs require authentication to access their data. You can provide authentication details using the <code>auth</code> parameter of the <code>requests.get()</code> or <code>requests.post()</code> methods.</span></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0e0e4-1c63-4374-a541-8c1f9d981c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7d5ac68-8065-458a-9f60-47b8e979eb36",
   "metadata": {},
   "source": [
    "<p><span style=\"font-size:16px;\">Challenge: Weather Forecast </span></p>\n",
    "\n",
    "<p><span style=\"font-size:16px;\">Write a Python program that uses the WeatherStack API to fetch the weather forecast for a specified city and display it to the user.</span></p>\n",
    "\n",
    "<p><span style=\"font-size:16px;\">Requirements:</span></p>\n",
    "\n",
    "<ol>\n",
    "\t<li><span style=\"font-size:16px;\">You need to sign up on the OpenWeatherMap website to get your API key. The API key is required to make requests to their API.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\">The program should prompt the user to enter the name of a city.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\">It should then make an HTTP GET request to the OpenWeatherMap API to fetch the weather data for the specified city.</span></li>\n",
    "\t<li><span style=\"font-size:16px;\">Parse the JSON response to extract and display the following information:</span></li>\n",
    "</ol>\n",
    "\n",
    "<ul style=\"margin-left: 40px;\">\n",
    "\t<li><span style=\"font-size:16px;\">City name</span></li>\n",
    "\t<li><span style=\"font-size:16px;\">Country</span></li>\n",
    "\t<li><span style=\"font-size:16px;\">Temperature (in Celsius)</span></li>\n",
    "\t<li><span style=\"font-size:16px;\">Weather description (e.g., sunny, cloudy, etc.)</span></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f9123-d46f-42a7-8495-c35685825fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_json = {\"request\":{\"type\":\"City\",\"query\":\"New York, United States of America\",\n",
    "                            \"language\":\"en\",\n",
    "                            \"unit\":\"m\"},\n",
    "                  \"location\":{\"name\":\"New York\",\n",
    "                              \"country\":\"United States of America\",\n",
    "                              \"region\":\"New York\",\n",
    "                              \"lat\":\"40.714\",\n",
    "                              \"lon\":\"-74.006\",\n",
    "                              \"timezone_id\":\"America\\/New_York\",\n",
    "                              \"localtime\":\"2023-07-19 21:06\",\n",
    "                              \"localtime_epoch\":1689800760,\n",
    "                              \"utc_offset\":\"-4.0\"},\n",
    "                  \"current\":{\"observation_time\":\"01:06 AM\",\n",
    "                             \"temperature\":25,\n",
    "                             \"weather_code\":143,\n",
    "                             \"weather_icons\":[\"https:\\/\\/cdn.worldweatheronline.com\\/images\\/wsymbols01_png_64\\/wsymbol_0006_mist.png\"],\n",
    "                             \"weather_descriptions\":[\"Haze\"],\n",
    "                             \"wind_speed\":4,\n",
    "                             \"wind_degree\":10,\n",
    "                             \"wind_dir\":\"N\",\n",
    "                             \"pressure\":1017,\n",
    "                             \"precip\":0,\n",
    "                             \"humidity\":77,\n",
    "                             \"cloudcover\":25,\n",
    "                             \"feelslike\":28,\n",
    "                             \"uv_index\":1,\n",
    "                             \"visibility\":8,\n",
    "                             \"is_day\":\"no\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ab168-5de9-44d1-987a-d3c6d8e26220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hidden API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1890f1a-9a16-4639-a901-94482a246db3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather_data(city):\n",
    "    #api_key = 'Get a Key'\n",
    "    url = f'http://api.weatherstack.com/current?access_key={api_key}&query={city}&units=m'\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        city_name = data[\"location\"][\"name\"]\n",
    "        country = data[\"location\"][\"country\"]\n",
    "        temperature = data[\"current\"][\"temperature\"]\n",
    "        weather_desc = data[\"current\"][\"weather_descriptions\"][0]\n",
    "\n",
    "        return city_name, country, temperature, weather_desc\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    city = input(\"Enter the name of a city: \")\n",
    "    weather_data = get_weather_data(city)\n",
    "\n",
    "    if weather_data:\n",
    "        city_name, country, temperature, weather_desc = weather_data\n",
    "        print(f\"\\nWeather Forecast for {city_name}, {country}:\")\n",
    "        print(f\"Temperature: {temperature}°C\")\n",
    "        print(f\"Weather: {weather_desc.capitalize()}\")\n",
    "    else:\n",
    "        print(\"Error fetching weather data. Please try again later.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded4c26-d84e-46ec-9489-d3481f2e111b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
